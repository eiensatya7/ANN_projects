{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "pycharm-53d5b8fb",
      "language": "python",
      "display_name": "PyCharm (pythonProject)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "miniproject_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eiensatya7/ANN_projects/blob/main/miniproject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pm_mbIZvX9G"
      },
      "source": [
        "# Problem :\n",
        "\n",
        "IMDB movie review sentiment classification problem. Each movie review is a variable sequence of words and the sentiment of each movie review must be classified. The IMDB Movie Review Dataset contains 25,000 highly-polar movie reviews (good or bad) for training and the same amount again for testing. The problem is to determine whether a given movie review has a positive or negative sentiment. Keras provides access to the IMDB dataset built-in. The imdb.load_data() function allows you to load the dataset in a format that is ready for use in neural network and deep learning models. The words have been replaced by integers that indicate the ordered frequency of each word in the dataset. The sentences in each review are therefore comprised of a sequence of integers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCqbxtfvvX9H"
      },
      "source": [
        "# Why CNN with LSTM for text Classifcation\n",
        "\n",
        "CNNs are generally used in computer vision, however they’ve recently been applied to various NLP tasks and the results were promising.\n",
        "Let’s briefly see what happens when we use CNN on text data through a diagram.The result of each convolution will fire when a special pattern is detected. By varying the size of the kernels and concatenating their outputs, you’re allowing yourself to detect patterns of multiples sizes (2, 3, or 5 adjacent words).Patterns could be expressions (word ngrams?) like “I hate”, “very good” and therefore CNNs can identify them in the sentence regardless of their position.\n",
        "Recurrent neural networks can obtain context information but the order of words will lead to bias; the text analysis method based on Convolutional neural network (CNN) can obtain important features of text through pooling but it is difficult to obtain contextual information which can be leverage using LSTM. So using the combination of CNN with LSTM could give us some intresting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd4wQ7CZvX9H"
      },
      "source": [
        "# Develop an text classification model based on CNN + LSTM in Keras.\n",
        "\n",
        "In this assignment, you will have to train two Text classification:\n",
        "1) LSTM based Text Classification\n",
        "2) CNN + LSTM based Text Classification\n",
        "\n",
        "After training the two different classification, you have to compare the F1 Score on both of the model trained and report the best F1 Score for which of them.\n",
        "\n",
        "This notebook is divided into six parts. Total : [12 Marks]\n",
        "\n",
        "1. Calculate the average length of reviews and modifying the length of sentences in X_train , X_test, X_cv [2 Mark]\n",
        "2. Implement the LSTM model [3 Marks]\n",
        "3. Calculate the LSTM model F1 Score [1 Mark]\n",
        "4. Implement the CNN + LSTM [3 Marks]\n",
        "5. Calculate the CNN + LSTM model F1 Score [1 Mark]\n",
        "6. Identify and decode 5 of the sentences misclassified by LSTM model which  were correctly classified by CNN + LSTM model [2 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsrle0cvvX9I"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential  # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense  # layers of the architecture\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#import the required library\n",
        "\n",
        "# Student will have to code here\n",
        "\n",
        "\n",
        "# Students will end their code here"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUnfSbvuvX9J",
        "outputId": "3e4dc798-64b2-4aa0-84ad-904c992ebf1d"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 10000\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.load.__defaults__ = (None, True, True, 'ASCII')\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(\"Shape of train data:\", X_train.shape)\n",
        "print(\"Shape of Test data:\", X_test.shape)\n",
        "print(\"Shape of CV data:\", X_cv.shape)\n",
        "\n",
        "print(X_train)\n",
        "\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train data: (20000,)\n",
            "Shape of Test data: (25000,)\n",
            "Shape of CV data: (5000,)\n",
            "[list([1, 427, 777, 1157, 14, 31, 47, 12, 32, 1006, 52, 548, 139, 599, 206, 3978, 525, 12, 82, 381, 4, 389, 2, 2, 17, 6195, 24, 2, 17, 4, 85, 2215, 3381, 46, 261, 2, 505, 83, 6195, 303, 23, 11, 4, 22, 490, 28, 8, 106, 12, 8, 67, 51, 13, 384, 10, 10, 13, 528, 1414, 8, 140, 83, 4, 65, 17, 45, 230, 99, 196, 2, 5, 24, 55, 221, 4, 649, 200, 6195, 5, 41, 597, 3281, 670, 2, 9, 221, 106, 4, 2, 3247, 136, 8, 67, 51, 13, 384, 10, 10, 4, 548, 139, 71, 33, 280, 179, 52, 5, 95, 2, 34, 49, 66, 5360, 599, 302, 15, 610, 40, 36, 71, 224, 34, 4, 768, 37, 122, 543, 7, 4, 1286, 351, 13, 963, 680, 2, 541, 2, 46, 7, 3307, 6367, 10, 10, 474, 4666, 451, 7, 364, 352, 1157, 8, 808, 12, 46, 48, 36, 70, 1406, 180, 6, 1039, 94, 184, 1281, 151, 5, 13, 426, 126, 67, 259, 8981, 8, 796, 766, 12, 38, 4092, 413, 32, 4, 2, 11, 6, 171, 153, 10, 10, 553, 474, 386, 12, 4402, 18, 2, 2, 87, 2516, 139, 15, 2, 6, 1675])\n",
            " list([1, 637, 974, 8, 112, 5391, 54, 13, 6801, 14, 237, 12, 16, 61, 2871, 8, 4, 201, 13, 219, 14, 22, 18, 4, 86, 58, 11, 3349, 23, 4, 522, 314, 1092, 2553, 23, 2, 63, 400, 2649, 3720, 5786, 40, 14, 46, 7, 1043, 2, 18, 162, 5122, 13, 93, 12, 6, 213, 8, 106, 4, 436, 2, 6828, 201, 159, 6695, 101, 7, 98, 133, 8, 97, 252, 13, 69, 1971, 267, 145, 13, 131, 967, 4, 313, 15, 2, 541, 17, 61, 514, 1477, 3280, 34, 2953, 39, 4, 8682, 5, 95, 5356, 10, 10, 13, 104, 32, 7, 4, 791, 15, 97, 14, 201, 1220, 4, 6629, 7493, 5819, 405, 627, 948, 8, 2, 230, 4190, 2953, 5, 4, 2152, 2, 7, 12, 32, 208, 180, 4, 9535, 228, 385, 295, 128, 133, 74, 101, 7, 4, 409, 444, 4, 20, 4615, 187, 6, 55, 154, 631, 704, 313, 5, 4, 6343, 15, 2, 32, 15, 2, 746, 10, 10, 4, 86, 65, 2290, 6, 189, 564, 5, 27, 322, 37, 1681, 83, 14, 9914, 273, 8, 79, 6, 989, 39, 4, 543, 38, 29, 100, 6470, 23, 27, 1797, 29, 2126, 6, 4041, 109, 446, 7333, 5, 515, 517, 6606, 87, 5654, 979, 635, 39, 1219, 50, 9, 6, 1302, 2, 133, 2864, 27, 8192, 15, 13, 258, 1139, 246, 948, 449, 5, 148, 527, 7916, 2698, 95, 174, 134, 26, 698, 156, 279, 148, 71, 147, 10, 10, 4, 333, 65, 9, 4, 787, 7, 6, 2610, 154, 132, 826, 6398, 15, 47, 1681, 133, 8, 1090, 27, 5293, 246, 12, 64, 2, 17, 29, 9, 2368, 34, 416, 119, 29, 186, 8, 28, 258, 614, 6317, 33, 6, 719, 55, 948, 5911, 4559, 21, 12, 505, 46, 29, 62, 28, 77, 76, 128, 125, 584, 10, 10, 4, 840, 65, 1687, 4, 87, 1368, 848, 61, 2, 698, 189, 284, 17, 6, 686, 336, 19, 6, 247, 4014, 5, 1562, 948, 185, 577, 29, 9, 1343, 2, 7, 41, 397, 83, 183, 59, 1616, 40, 6413, 59, 47, 6, 1249, 676, 18, 12, 19, 52, 282, 848, 9, 897, 133, 17, 4, 1903, 1043, 2, 15, 132, 47, 6, 283, 676, 18, 395, 105, 15, 26, 427, 4170, 7, 4830, 21, 466, 27, 118, 2048, 4, 117, 2, 127, 11, 192, 850, 4078, 1857, 5, 78, 183, 794, 10, 10, 14, 477, 65, 9, 4, 787, 7, 6, 3071, 154, 2496, 284, 15, 764, 4, 185, 167, 240, 780, 19, 218, 2, 8, 1839, 6, 2261, 1362, 22, 208, 180, 8, 4, 489, 7, 4, 1352, 5, 27, 8101, 11, 843, 38, 29, 271, 8, 6, 154, 3616, 1130, 11, 4, 655, 7, 6, 2, 314, 8, 79, 142, 53, 2902, 117, 127, 29, 124, 15, 29, 1637, 56, 6, 371, 2902, 2, 8101, 1489, 12, 23, 33, 4, 6647, 7, 2927, 47, 247, 6456, 302, 34, 4, 58, 13, 69, 1840, 8, 14, 2770, 5, 477, 65, 12, 16, 103, 342, 244, 5, 13, 426, 179, 789, 4141, 23, 4, 86, 353, 24, 39, 3262, 21, 13, 122, 585, 142, 15, 13, 28, 3103, 7, 211, 6, 1997, 9398, 585, 13, 28, 19, 108, 42, 228, 54, 13, 7895, 11, 5, 46, 7, 1666, 5, 4, 22, 228, 461, 173, 7, 61, 925, 87, 253, 14, 1162, 65, 16, 404, 18, 15, 5, 468, 76, 8538, 4, 86, 58, 74, 12, 165, 16, 88, 13, 9410, 56, 208, 54, 29, 16, 2, 34, 4, 2, 671, 5, 426, 179, 6685, 16, 51, 1448, 33, 86, 24, 196, 103, 4, 1334, 6195, 2743, 6, 2, 23, 27, 20, 270, 385, 8, 1980, 5, 29, 2815, 41, 24, 8, 276, 23, 4, 8101, 33, 2927, 21, 29, 2, 28, 2627, 18, 59, 16, 6, 147, 1362, 765, 4, 2, 9683, 2, 15, 1477, 17, 59, 8754, 1841, 90, 23, 4, 2, 16, 331, 3791, 5, 174, 11, 61, 320, 2359, 1110, 468, 247, 1499, 499, 854, 97, 252, 8, 1277, 848, 5, 2743, 367, 19, 4, 1380, 2, 323, 2, 2, 11, 4, 32, 58, 356, 22, 4, 9941, 132, 4827, 10, 10, 4, 4343, 4304, 133, 16, 4, 2, 1702, 200, 537, 21, 448, 23, 4, 537, 533, 14, 9, 6, 356, 2, 13, 62, 135, 4, 840, 65, 9, 118, 21, 13, 40, 4, 6033, 91, 88, 12, 166, 72, 1826, 38, 76, 55, 545, 1178, 18, 189, 451, 5, 48, 335, 6, 698, 189, 337, 45, 9017, 474, 135, 45, 2640, 8, 650, 4, 201, 11, 2, 661, 48, 25, 70, 4, 236, 22, 7, 14, 201, 969, 1333, 4292, 9, 434, 4, 4343, 13, 104, 4, 86, 342, 470, 108, 549, 18, 4, 33, 211, 1501, 1789, 4056, 7170, 26, 4, 118, 21, 48, 25, 40, 101, 7, 98, 25, 144, 106, 98, 32, 33, 222, 280, 490, 242, 30, 145, 111, 53, 211, 8, 106, 129, 2635])\n",
            " list([1, 6568, 47, 69, 2557, 1023, 120, 4, 153, 19, 4, 368, 1615, 1683, 1125, 102, 36, 28, 93, 6, 7237, 113, 16, 4, 333, 7, 6, 226, 762, 7, 944, 36, 28, 93, 38, 230, 2, 34, 4, 2, 792, 1615, 2016, 4, 8616, 2888, 65, 63, 16, 4, 86, 126, 792, 1615, 1683, 20, 13, 377, 54, 14, 794, 56, 16, 2699, 6160, 187, 4, 58, 7, 94, 766, 11, 4, 522, 8111, 21, 13, 115, 165, 219, 12, 366, 9561, 2945, 13, 296, 12, 1453, 15, 3241, 5, 120, 289, 153, 303, 13, 28, 110, 12, 6, 840, 58, 12, 47, 115, 1555, 72, 17, 76, 17, 242, 101, 85, 6568, 22, 207, 126, 110, 21, 103, 289, 4719, 13, 131, 104, 45, 128, 74, 49, 7, 4, 108, 207, 110, 39, 2, 748, 10, 10, 2, 1111, 9, 4, 344, 7, 6, 8184, 7, 5859, 134, 5859, 26, 918, 8, 5231, 1644, 18, 6, 1366, 7, 2, 37, 216, 5, 193, 12, 175, 291, 31, 1679, 7, 14, 8184, 9, 2, 35, 2, 19, 6, 78, 2577, 18, 4052, 1113, 19, 27, 2, 60, 151, 29, 152, 384, 8, 31, 291, 54, 4, 8184, 47, 43, 1769, 6083, 4, 2, 3991, 2, 2507, 6635, 12, 83, 6, 6850, 43, 159, 4, 2, 3854, 8, 79, 12, 4, 2, 2121, 4675, 1068, 8, 202, 98, 6, 333, 580, 8, 5231, 1644, 5, 28, 12, 1623, 34, 4, 130, 7, 4, 811, 21, 36, 80, 28, 8, 1405, 68, 3991, 2, 3188, 8, 4, 2, 4876, 2, 15, 29, 271, 5, 659, 3745, 3096, 8, 548, 125, 4, 2, 54, 36, 216, 145, 2549, 2, 4, 705, 1652, 1625, 90, 140, 23, 14, 1973, 43, 38, 29, 528, 30, 187, 8, 1203, 1113, 137, 4, 8184, 497, 8, 5231, 1644, 18, 160, 3991, 4, 2, 659, 6, 604, 7, 3096, 63, 29, 1291, 26, 5197, 21, 103, 29, 304, 98, 145, 8, 2, 1111, 5, 4319, 98, 29, 2271, 15, 36, 26, 165, 24, 5197, 21, 5601, 3096, 10, 10, 4, 293, 282, 138, 14, 333, 6568, 792, 47, 115, 427, 2, 72, 238, 30, 4, 105, 8, 72, 600, 7, 98, 28, 126, 66, 3405, 46, 17, 76, 17, 36, 100, 28, 5, 1228, 306, 6, 227, 1904, 2994, 190, 45, 24, 40, 3310, 787, 6, 22, 19, 6, 55, 3192, 5, 5312, 485, 109, 6, 7237, 113, 127, 28, 6, 1451, 195, 293, 109, 31, 63, 797, 70, 3663, 18, 4, 65, 82, 186, 643, 1904, 33, 211, 21, 18, 4, 91, 173, 45, 52, 195, 8, 401, 4, 22, 33, 222, 8995, 441, 5, 518, 47, 49, 52, 836, 262, 303, 23, 4, 1285, 40, 813, 85, 1409, 7, 4, 22, 218, 17, 52, 17, 12, 100, 28, 77, 21, 50, 26, 407, 163, 388, 49, 7, 98, 1237, 4804, 6, 915, 2, 37, 9, 518, 4074, 18, 6, 668, 25, 70, 210, 535, 87, 748, 39, 6568, 5, 4, 748, 11, 14, 843, 781, 7, 9130, 9, 57, 1401, 19, 32, 14, 20, 47, 8, 1464, 12, 203, 30, 1076, 1332, 54, 12, 266, 8, 6568, 1553, 21, 12, 9, 3793, 223, 722])\n",
            " ...\n",
            " list([1, 17, 13, 301, 4, 274, 16, 184, 52, 5, 14, 238, 28, 77, 6, 52, 20, 48, 6103, 7086, 1869, 77, 38, 527, 5, 1297, 11, 4, 485, 1686, 51, 243, 7, 1191, 16, 15, 1408, 8, 30, 553, 12, 2774, 4, 172, 17, 41, 527, 1766, 1191, 11, 160, 20, 15, 13, 28, 110, 41, 11, 175, 58, 59, 3057, 41, 1642, 13, 2, 12, 562, 342, 497, 159, 13, 16, 502, 8, 106, 4, 436, 20, 2782, 2820, 16, 52, 17, 4, 85, 485, 10, 10, 13, 66, 423, 4, 2583, 1622, 139, 36, 1283, 49, 76, 887, 2, 8, 193, 129, 330, 125, 7, 6103, 2, 2279, 1146, 13, 104, 36, 100, 28, 343, 2614, 3698, 2692, 53, 8, 68, 3079, 151, 12, 610, 40, 4, 314, 139, 71, 165, 6499, 21, 13, 100, 30, 355, 13, 92, 2283, 4, 109, 11, 4, 274, 112, 14, 2279, 10, 10, 591, 401, 6103, 7086, 46, 7, 101, 705, 102, 15, 5276, 35, 1191])\n",
            " list([1, 7, 32, 4, 698, 2, 102, 40, 689, 2, 2909, 7, 4, 641, 2, 18, 463, 14, 20, 1407, 46, 17, 4, 5234, 7, 4, 9687, 12, 5613, 6, 58, 54, 4, 2739, 115, 270, 23, 4, 698, 3806, 79, 120, 12, 13, 528, 140, 83, 138, 88, 38, 111, 409, 28, 4977, 4, 111, 1007, 15, 166, 14, 22, 87, 13, 28, 5368, 4, 2, 3184, 5, 28, 3551, 4, 1345, 143, 63, 4, 698, 2, 5, 12, 1287, 17, 12, 16, 2, 34, 58, 5, 2, 34, 132, 5, 2, 5, 60, 151, 13, 124, 45, 582, 319, 5143, 3173, 351, 23, 6, 2, 5, 54, 134, 411, 26, 332, 10, 10, 422, 5143, 5143, 5143, 10, 10, 25, 2, 5921, 5959, 5143, 10, 10, 151, 207, 2, 25, 5, 2, 25, 10, 10, 34, 4, 2, 2, 15, 93, 25, 10, 10, 335, 6, 128, 132, 74, 13, 244, 5959, 5143, 10, 10, 13, 131, 33, 2, 153, 7, 559, 79, 7594, 3406, 5, 259, 37, 560, 36, 92, 9, 6, 9504, 4, 2202, 7, 1438, 746, 12, 9, 4, 951, 7, 6, 87, 20, 40, 4, 277, 7, 160, 87, 22, 7, 6302, 5, 349])\n",
            " list([1, 1864, 13, 28, 447, 2368, 313, 102, 141, 17, 2, 5, 2, 14, 93, 18, 248, 6638, 7, 2787, 3184, 274, 6510, 6, 666, 2845, 23, 4, 3645, 7, 363, 10, 10, 19, 6, 530, 177, 111, 7, 63, 323, 11, 2, 5, 85, 248, 3287, 87, 116, 5, 777, 956, 63, 2235, 2, 113, 4521, 12, 47, 32, 4, 208, 4048, 8, 2, 4, 529, 83, 51, 9, 6, 976, 1213, 65, 10, 10, 6992, 1567, 122, 24, 359, 541, 567, 42, 599, 8, 2222, 5433, 180, 4, 2, 7, 35, 311, 772, 129, 205, 1546, 4, 255, 11, 328, 9, 6, 822, 7, 1092, 5, 6249, 5, 625, 1369, 9, 115, 4948, 280, 59, 86, 739, 10, 10, 4, 293, 109, 1607, 2, 6, 2, 2271, 44, 27, 4957, 2, 23, 27, 1973, 8, 4184, 4, 3519, 4, 4370, 1442, 5, 1607, 2617, 171, 3527, 1004, 41, 4734, 344, 11, 63, 29, 8132, 111, 2, 63, 203, 7370, 90, 18, 49, 504, 49, 7, 4, 139, 26, 55, 4333, 5, 5773, 572, 4, 2897, 673, 63, 2013, 410, 63, 505, 4, 2, 125, 5, 2, 1607, 11, 2601, 4, 22, 461, 53, 7633, 4, 53, 25, 276, 624, 11, 2, 3730, 5, 27, 2048, 8, 4464, 14, 1213, 125, 4, 564, 1457, 111, 2860, 2, 83, 4, 65, 35, 463, 112, 4, 8172, 2, 796, 1267, 31, 9, 4511, 8, 850, 4, 1217, 7, 12, 32, 4, 192, 75, 115, 66, 850, 15, 76, 44, 4, 4370, 889, 53, 8, 4, 1546, 5, 166, 12, 32, 4, 53, 4333, 10, 10, 4, 4370, 18, 4, 91, 173, 272, 3839, 5, 2, 4, 136, 103, 2, 4, 2, 1412, 4, 5433, 180, 72, 6, 255, 37, 739, 46, 7, 1282, 23, 4383, 2, 1541, 19, 6, 8048, 1933, 475, 260, 77, 23, 141, 2, 546, 13, 70, 1144, 89, 2, 14, 9, 5, 4, 136, 11, 4, 2, 16, 382, 4, 91, 527, 183, 207, 110, 31, 13, 92, 657, 8, 106, 11, 6, 8605, 42, 123, 8, 3715, 4784, 13, 28, 400, 2, 56, 33, 314, 536, 59, 16, 496, 72, 11, 61, 1666, 10, 10, 4, 255, 11, 328, 9, 6, 87, 248, 20, 5, 6, 416, 1528, 13, 1041, 8, 49, 2826, 4, 3077, 3401, 18, 14, 22, 47, 77, 484, 6648, 5, 70, 67, 138, 84, 71, 685, 103, 3427, 4, 118, 7, 2, 23, 12, 21, 13, 104, 4, 5784, 47, 5765, 1599, 5786, 88, 12, 166, 108, 40, 134, 120, 3773, 13, 104, 45, 131, 530, 5, 9708, 917, 5, 13, 1133, 12, 4, 833, 1213, 65, 7, 4, 236, 1117])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXI9dZl3vX9J",
        "outputId": "98b9f5f1-7770-4c52-83b0-419833a36ec5"
      },
      "source": [
        "def get_avg_length(data):\n",
        "    review_length = []\n",
        "    largest_length = 0\n",
        "    smallest_length = 1000000\n",
        "    for review in data:\n",
        "        length = len(review)\n",
        "        largest_length = length if largest_length < length else largest_length\n",
        "        smallest_length = length if smallest_length > length else smallest_length\n",
        "        review_length.append(length)\n",
        "    average_review_length = int(np.ceil(np.mean(review_length)))\n",
        "    return average_review_length, largest_length, smallest_length\n",
        "\n",
        "\n",
        "# truncate and pad input sequences\n",
        "# Calculate the average length of reviews using the training set (X_train) and set the value to max_review_length\n",
        "# truncate or pad the reviews so that length of all the reviews are same\n",
        "\n",
        "average_review_length, largest_length, smallest_length = get_avg_length(X_train)\n",
        "\n",
        "print(\n",
        "    f\"average review length {average_review_length}, smallest review length {smallest_length}, largest review length {largest_length}\")\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=average_review_length, padding='post',\n",
        "                        truncating='post')  # code to truncate or pad the reviews to the average_review_length\n",
        "X_test = pad_sequences(X_test, maxlen=average_review_length, padding='post',\n",
        "                       truncating='post')  # code to truncate or pad the reviews to the average_review_length\n",
        "X_cv = pad_sequences(X_cv, maxlen=average_review_length, padding='post',\n",
        "                     truncating='post')\n",
        "\n",
        "print(\"Padded and truncated posts\")\n",
        "\n",
        "average_review_length, largest_length, smallest_length = get_avg_length(X_train)\n",
        "print(\n",
        "    f\"average review length {average_review_length}, smallest review length {smallest_length}, largest review length {largest_length}\")\n",
        "\n",
        "# code to truncate or pad the reviews to the average_review_length"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average review length 238, smallest review length 11, largest review length 1629\n",
            "Padded and truncated posts\n",
            "average review length 238, smallest review length 238, largest review length 238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LFZ5a40vX9K",
        "outputId": "13d498c3-d8ca-4b72-9ddf-c8b184b1cb1f"
      },
      "source": [
        "# Decoding the data coded data of IMDB ( Data Understanding )\n",
        "index = imdb.get_word_index()\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
        "decoded = \" \".join([reverse_index.get(i - 3, \"#\") for i in X_train[0]])\n",
        "print(decoded)\n",
        "\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# absolutely fantastic trash this one has it all nudity good fight scenes gore action explosions etc it also stars the wonderful # # as ingrid not # as the other reviewer pointed out although # turns into ingrid later on in the film you'll have to watch it to see what i mean br br i won't bother to go into the story as it's far too long # and not very interesting the relationship between ingrid and her brother bo robert # is interesting watch the # stealing scene to see what i mean br br the fight scenes were at once quite good and then # by some really shoddy gore effects that looked like they were done by the team who did city of the walking dead i e strange # blood # out of neck wounds br br i'd advise fans of low budget trash to check it out if they can track down a copy its pretty rare though and i couldn't ever see anyone bothering to re release it so it'll become all the # in a few years br br anyway i'd recommend it solely for # # great nude scenes that # a fox # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjbDflsuvX9L"
      },
      "source": [
        "# Architecture Diagram for LSTM Based Classifcation but you will have to change the\n",
        "# configuration/model parameters while implementing it depending on the input , output and the \n",
        "# Problem statement.\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "#Image(filename='LSTM_model.png')\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opgqid3nvX9L",
        "outputId": "1414d988-d048-4c78-c454-3717e85a3db4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "embedding_vector_length = 64\n",
        "model_lstm = tf.keras.Sequential()\n",
        "\n",
        "# Write the code for LSTM Based Classifcation\n",
        "# Embedding layer\n",
        "# LSTM Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# Dense Layer\n",
        "# Use appropriate activation function in respective layers\n",
        "\n",
        "# Students will be starting their code from here:\n",
        "\n",
        "model_lstm.add(Embedding(10000, embedding_vector_length, input_length = average_review_length))\n",
        "model_lstm.add(LSTM(128))\n",
        "model_lstm.add(Dense(2, activation='relu'))\n",
        "\n",
        "# Students will be ending their code here\n",
        "\n",
        "\n",
        "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model_lstm.summary())\n",
        "\n",
        "# Change the number of epochs and the batch size depending on the RAM Size\n",
        "\n",
        "model_lstm.fit(X_train, y_train, epochs=1, batch_size=64, verbose=1, validation_data=(X_cv, y_cv))\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_24 (Embedding)     (None, 238, 64)           640000    \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 739,074\n",
            "Trainable params: 739,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "313/313 [==============================] - 170s 536ms/step - loss: 0.7106 - accuracy: 0.5045 - val_loss: 0.6766 - val_accuracy: 0.5118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b668df990>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXcin8axvX9M",
        "outputId": "7ae5b3ab-2dca-4878-db90-cadb003cfedd"
      },
      "source": [
        "# Final evaluation of the model using test dataset\n",
        "# Students will be starting their code from here:\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "\n",
        "yhat_probs = model_lstm.predict(X_test, verbose=0)\n",
        "\n",
        "\n",
        "print(yhat_probs)\n",
        "\n",
        "y_pred=np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(f'Classification report: {cr}')\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy score: {accuracy}')\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "print(f'F1 score: {f1}')\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "print(f\"Recall: {recall}\")\n",
        "\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.4581262  0.47105297]\n",
            " [0.45332924 0.4810728 ]\n",
            " [0.5963305  0.579344  ]\n",
            " ...\n",
            " [0.45812604 0.47105277]\n",
            " [0.45812604 0.47105277]\n",
            " [0.45815742 0.47108948]]\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.14      0.22     12500\n",
            "           1       0.50      0.86      0.63     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.50      0.50      0.43     25000\n",
            "weighted avg       0.50      0.50      0.43     25000\n",
            "\n",
            "Accuracy score: 0.50104\n",
            "F1 score: 0.4268221684430639\n",
            "Recall: 0.50104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LF4LFNRHOOv"
      },
      "source": [
        "\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7qxt7eqvX9M"
      },
      "source": [
        "# High Level Model Architecture\n",
        "from IPython.display import Image\n",
        "\n",
        "#Image(filename='1_VGtBedNuZyX9E-07gnm2Yg.png')\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFQknMUtvX9M",
        "outputId": "45f49ba2-32bc-44bc-e30b-b85bf860478e"
      },
      "source": [
        "# create the model\n",
        "\n",
        "from tensorflow.keras.layers import MaxPooling1D, Conv1D, Flatten, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "embedding_vector_length = 64\n",
        "model_cnn_lstm = Sequential()\n",
        "\n",
        "# Students will be starting their code from here:\n",
        "\n",
        "# Write the code for LSTM Based Classifcation\n",
        "# Embedding layer\n",
        "# Convolution-1D Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# LSTM Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# Dense Layer\n",
        "# Use appropriate activation function in respective layers\n",
        "\n",
        "\n",
        "# Students will be ending their code here\n",
        "\n",
        "model_cnn_lstm.add(Embedding(10000, embedding_vector_length, input_length = average_review_length))\n",
        "\n",
        "model_cnn_lstm.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model_cnn_lstm.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn_lstm.add(LSTM(128))\n",
        "model_cnn_lstm.add(Dense(2, activation='relu'))\n",
        "\n",
        "model_cnn_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model_cnn_lstm.summary())\n",
        "\n",
        "# Change the number of epochs and the batch size depending on the RAM Size\n",
        "\n",
        "model_cnn_lstm.fit(X_train, y_train, epochs=1, batch_size=64, verbose=1, validation_data=(X_cv, y_cv))\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 238, 64)           640000    \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 238, 32)           6176      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 119, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 128)               82432     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 728,866\n",
            "Trainable params: 728,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "313/313 [==============================] - 89s 279ms/step - loss: 0.7230 - accuracy: 0.5077 - val_loss: 0.6649 - val_accuracy: 0.4614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b5c726510>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZuYwSFXvX9N",
        "outputId": "669e6fb8-7982-4f60-dca3-cb80e894c0cf"
      },
      "source": [
        "# Final evaluation of the CNN + RNN model using the test data\n",
        "# Students will be starting their code from here:\n",
        "\n",
        "yhat_probs_cl = model_cnn_lstm.predict(X_test, verbose=0)\n",
        "\n",
        "\n",
        "print(yhat_probs_cl)\n",
        "\n",
        "y_pred_cl=np.argmax(yhat_probs_cl,axis=1)\n",
        "\n",
        "\n",
        "cr = classification_report(y_test, y_pred_cl)\n",
        "print(f'Classification report: {cr}')\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_cl)\n",
        "print(f'Accuracy score: {accuracy}')\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_cl, average='weighted', labels=np.unique(y_pred_cl))\n",
        "print(f'F1 score: {f1}')\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, y_pred_cl, average='weighted', labels=np.unique(y_pred_cl))\n",
        "print(f\"Recall: {recall}\")\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.51844394 0.5173932 ]\n",
            " [0.6244066  0.5970866 ]\n",
            " [0.4530188  0.45486316]\n",
            " ...\n",
            " [0.518444   0.5173932 ]\n",
            " [0.51843953 0.5173897 ]\n",
            " [0.51776206 0.5168567 ]]\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.77      0.59     12500\n",
            "           1       0.41      0.16      0.23     12500\n",
            "\n",
            "    accuracy                           0.47     25000\n",
            "   macro avg       0.45      0.47      0.41     25000\n",
            "weighted avg       0.45      0.47      0.41     25000\n",
            "\n",
            "Accuracy score: 0.46588\n",
            "F1 score: 0.4104293326451592\n",
            "Recall: 0.46588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohn9hXXmvX9N",
        "outputId": "26f64efb-7e6b-4eb2-c2cb-2cc1dc77b564"
      },
      "source": [
        "# Identify and decode 5 of the sentences misclassified by LSTM model which  were correctly classified by CNN + LSTM model\n",
        "# Students will be starting their code from here:\n",
        "nos = 5\n",
        "count = 0\n",
        "\n",
        "\n",
        "SentimentDict={1:'positive', 0:'negative'}\n",
        "\n",
        "def get_original_text(xt):\n",
        "  index = imdb.get_word_index()\n",
        "  reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
        "  decoded = \" \".join([reverse_index.get(i - 3, \"#\") for i in xt])\n",
        "  return decoded\n",
        "\n",
        "\n",
        "def display_test_sentiment(xt, yt, yp):\n",
        "    print(get_original_text(xt))\n",
        "    print('label: ', SentimentDict[yt], ', prediction: ', SentimentDict[yp])\n",
        "\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "  xt = X_test[i]\n",
        "  yt = y_test[i]\n",
        "  yp = y_pred[i]\n",
        "  yp_cl = y_pred_cl[i]\n",
        "  print('label: ', yt, ', LSTM prediction: ', yp, ', CNN LSTM prediction: ', yp_cl)\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  xt = X_test[i]\n",
        "  yt = y_test[i]\n",
        "  yp = y_pred[i]\n",
        "  yp_cl = y_pred_cl[i]\n",
        "\n",
        "\n",
        "\n",
        "  if yt != yp and yt == yp_cl :\n",
        "      print(get_original_text(xt))\n",
        "      print('label: ', SentimentDict[yt], ', LSTM prediction: ', SentimentDict[yp], ', CNN LSTM prediction: ', SentimentDict[yp_cl])\n",
        "      count = count + 1\n",
        "      if count == nos :\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  0 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  0 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  0 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  0 , CNN LSTM prediction:  1\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  1\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  1 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "label:  0 , LSTM prediction:  1 , CNN LSTM prediction:  0\n",
            "# please give this one a miss br br # # and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite # so all you madison fans give this a miss # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
            "label:  negative , LSTM prediction:  positive , CNN LSTM prediction:  negative\n",
            "# many animation buffs consider # # the great forgotten genius of one special branch of the art puppet animation which he invented almost single # and as it happened almost accidentally as a young man # was more interested in # than the cinema but his # attempt to film two # # fighting led to an unexpected breakthrough in film making when he realized he could # movement by # beetle # and # them one frame at a time this discovery led to the production of amazingly elaborate classic short the # revenge which he made in russia in # at a time when motion picture animation of all sorts was in its # br br the political # of the russian revolution caused # to move to paris where one of his first productions # was a dark political satire # known as # or the # who wanted a king a strain of black comedy can be found in almost all of films but here it is very dark indeed aimed more at grown ups who can appreciate the satirical aspects than children who would most likely find the climax # i'm middle aged and found it pretty # myself and indeed # of the film intended for english speaking viewers of the 1920s were given title cards filled with # and # in order to help # the sharp # of the\n",
            "label:  positive , LSTM prediction:  negative , CNN LSTM prediction:  positive\n",
            "# i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people are absolute idiots i am a grown man pretty big and i can defend myself well however i would not do half the stuff the little girl does in this movie also the mother in this movie is reckless with her children to the point of neglect i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are # involved with the actions on the screen so then why the hell can't we have night vision # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
            "label:  negative , LSTM prediction:  positive , CNN LSTM prediction:  negative\n",
            "# hollywood had a long love affair with bogus # nights tales but few of these products have stood the test of time the most memorable were the jon hall maria # films which have long since become camp this one is filled with dubbed songs # # and slapstick it's a truly crop of corn and pretty near # today it was nominated for its imaginative special effects which are almost # in this day and age # mainly of trick photography the only outstanding positive feature which survives is its beautiful color and clarity sad to say of the many films made in this genre few of them come up to alexander # original thief of # almost any other # nights film is superior to this one though it's a loser # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
            "label:  negative , LSTM prediction:  positive , CNN LSTM prediction:  negative\n",
            "# when i first saw this movie in the theater i was so angry it completely blew in my opinion i didn't see it for a decade then decided what the hell let's see i'm watching all # movies now to see where it went wrong my guess is it was with sequel 5 that was the first to # the whole i am in a dream # i see weird stuff oh # what is happening oh its a dream oh its not a dream oh wait i see something spooky oh never mind # storyline those sequels don't even require the box to be opened or stick to the rules from the first 4 movies that if you saw # you are pretty much screwed and dead the first 3 # to this storyline which made it so scary in the first place nothing fantasy nothing weird the box got opened boom they came was the only one that could bargain her way out of it first because of uncle frank then because she had information about the this movie at least attempts to stick to all that even though it was a bad story it was still somewhat # no i'm pretty sure part 5 was the first part to completely and utterly destroy the # series now they are # 1 and i don't even think i will watch it oh who am i\n",
            "label:  negative , LSTM prediction:  positive , CNN LSTM prediction:  negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wXlRw4TvX9N"
      },
      "source": [
        ""
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFb4l4nrvX9N"
      },
      "source": [
        ""
      ],
      "execution_count": 137,
      "outputs": []
    }
  ]
}